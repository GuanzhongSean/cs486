{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 486/686 Assignment 3\n",
    "\n",
    "## Question 1\n",
    "\n",
    "### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1000', '9000', '0100', '0900', '0010', '0090', '0001', '0009']\n",
      "['1100', '9100', '0200', '0000', '0110', '0190', '0109']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_successors(cur: str) -> List[str]:\n",
    "    dangerous_states = {\"0201\", \"0101\", \"0102\", \"1212\", \"2002\"}\n",
    "    successors = []\n",
    "\n",
    "    for i in range(4):\n",
    "        num = int(cur[i])\n",
    "        for change in [1, -1]:\n",
    "            new_num = (num + change) % 10\n",
    "            new_state = cur[:i] + str(new_num) + cur[i+1:]\n",
    "            if new_state not in dangerous_states:\n",
    "                successors.append(new_state)\n",
    "\n",
    "    return successors\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(get_successors(\"0000\"))\n",
    "    print(get_successors(\"0100\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "TARGET = \"0202\"\n",
    "\n",
    "def search() -> int: # BFS\n",
    "    frontier = deque([(\"0000\", 0)])\n",
    "\n",
    "    while frontier:\n",
    "        current_state, turns = frontier.popleft()\n",
    "        if current_state == TARGET:\n",
    "            return turns\n",
    "\n",
    "        for successor in get_successors(current_state):\n",
    "            frontier.append((successor, turns + 1))\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(search())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def dfs(limit: int) -> int:\n",
    "    frontier = [(\"0000\", 0)]\n",
    "\n",
    "    while frontier:\n",
    "        current_state, turns = frontier.pop()\n",
    "        if current_state == TARGET:\n",
    "            return turns\n",
    "\n",
    "        if turns == limit:\n",
    "            continue\n",
    "\n",
    "        for successor in get_successors(current_state):\n",
    "            frontier.append((successor, turns + 1))\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "MAX_DEPTH = 20 # K\n",
    "\n",
    "\n",
    "def ids_search() -> int:\n",
    "    depth = 1\n",
    "    while depth <= MAX_DEPTH:\n",
    "        result = dfs(depth)\n",
    "        if result != -1:\n",
    "            return result\n",
    "        depth += 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(ids_search())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is IDS guaranteed to find a solution if it exists?**\n",
    "- Yes, IDS is complete. It will find the solution if it exists because it explores all depths incrementally, ensuring that no state is left unexplored within the maximum depth.\n",
    "\n",
    "**Space Complexity:**\n",
    "- The space complexity of IDS is $O(bM)$, where $b$ is the branching factor, and $M$ is the depth of the goal node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def get_heuristic(cur: str) -> int:\n",
    "    heuristic = 0\n",
    "    for i in range(4):\n",
    "        cur_digit = int(cur[i])\n",
    "        target_digit = int(TARGET[i])\n",
    "        distance = abs(cur_digit - target_digit)\n",
    "        distance = min(distance, 10 - distance)\n",
    "        heuristic += distance\n",
    "    return heuristic\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(get_heuristic(\"0000\"))\n",
    "    print(get_heuristic(\"1234\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Manhattan distance is admissible because it never overestimates the true cost to reach the goal. In this problem, the Manhattan distance represents the minimum number of moves required to match each digit in the current state to the corresponding digit in the target state.\n",
    "\n",
    "The Manhattan distance heuristic for a lock state is computed by summing the absolute differences between the digits of the current state and the target state. Since each wheel can wrap around, we take the minimum number of clockwise and anti-clockwise turns (e.g., moving from 9 to 0 is a single move)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)\n",
    "\n",
    "**Manhattan Distance Consistency**:\n",
    "- When you move from state $n$ to a neighbour state $m$ by turning a wheel by one position, the Manhattan distance decreases by at most one, hence $ h(n) - h(m) \\leq cost(n, m) = 1 $ holds true.\n",
    "\n",
    "Thus, as the Manhattan distance heuristic is consistent, ensuring that A* search with multi-path pruning remains optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f)\n",
    "\n",
    "Minimum number of turns: 6\n",
    "\n",
    "0000 -> 0100 -> 0200 -> 1200 -> 1201 -> 1202 -> 0202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "# Those libraries should be enough for your implementation.\n",
    "# Do not change the existing function signatures in this file.\n",
    "\n",
    "random.seed(486686)\n",
    "\n",
    "\n",
    "def generate_neighbor(given_items: List[Tuple[int, int]], selection: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Given a list of items to choose from and a current selection,\n",
    "    returns a neighboring selection by randomly adding or removing an item.\n",
    "\n",
    "    :param given_items: a list of items to choose from\n",
    "    :param selection: a current selection\n",
    "    :return: a neighboring selection\n",
    "    \"\"\"\n",
    "\n",
    "    neighbor = selection[:]\n",
    "    i = random.randint(0, len(given_items) - 1)\n",
    "    if neighbor[i] > 0:\n",
    "        neighbor[i] += random.choice([-1, 1])\n",
    "    else:\n",
    "        neighbor[i] += 1\n",
    "    return neighbor\n",
    "\n",
    "\n",
    "def knapsack_solver(capacity: int, items: List[Tuple[int, int]]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Given a list of items to choose from and a maximum capacity of a knapsack,\n",
    "    returns a selection of items that maximize the total value of items in the knapsack\n",
    "    through the Simulated Annealing Algorithm.\n",
    "\n",
    "    :param capacity: the maximum capacity of the knapsack\n",
    "    :param items: a list of items to choose from (weight, value)\n",
    "    :return: a selection of items that maximize the total value of items in the knapsack\n",
    "    \"\"\"\n",
    "\n",
    "    def calculate_total_value(selection: List[int]) -> int:\n",
    "        nonlocal items\n",
    "        return sum(selection[i] * items[i][1] for i in range(len(items)))\n",
    "\n",
    "    def calculate_total_weight(selection: List[int]) -> int:\n",
    "        nonlocal items\n",
    "        return sum(selection[i] * items[i][0] for i in range(len(items)))\n",
    "\n",
    "    # Initial selection\n",
    "    current_selection = [0] * len(items)\n",
    "    current_value = 0\n",
    "    best_selection = current_selection[:]\n",
    "    best_value = current_value\n",
    "\n",
    "    # Simulated annealing parameters\n",
    "    T = 1000.0\n",
    "    cooling_rate = 0.99\n",
    "    min_T = 0.01\n",
    "\n",
    "    while T > min_T:\n",
    "        neighbor_selection = generate_neighbor(items, current_selection)\n",
    "        if calculate_total_weight(neighbor_selection) <= capacity:\n",
    "            neighbor_value = calculate_total_value(neighbor_selection)\n",
    "            delta_value = neighbor_value - current_value\n",
    "\n",
    "            if delta_value > 0 or math.exp(delta_value / T) > random.random():\n",
    "                current_selection = neighbor_selection\n",
    "                current_value = neighbor_value\n",
    "\n",
    "            if current_value > best_value:\n",
    "                best_selection = current_selection[:]\n",
    "                best_value = current_value\n",
    "\n",
    "            T *= cooling_rate\n",
    "\n",
    "    return best_selection\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    capacity = 50\n",
    "    items = [(10, 60), (20, 200), (30, 120)]\n",
    "    result = knapsack_solver(capacity, items)\n",
    "    expected = [1, 2, 0]\n",
    "    if result == expected:\n",
    "        print(\"Pass\")\n",
    "    else:\n",
    "        print(\"Incorrect\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "\n",
    "def parse_input(input_string):\n",
    "    lines = input_string.strip().split('\\n')\n",
    "    pacman_pos = tuple(map(int, lines[0].split()))\n",
    "    food_pos = tuple(map(int, lines[1].split()))\n",
    "    rows, cols = map(int, lines[2].split())\n",
    "    grid = [list(line) for line in lines[3:3 + rows]]\n",
    "    return pacman_pos, food_pos, grid, rows, cols\n",
    "\n",
    "\n",
    "def manhattan_distance(start, end):\n",
    "    return abs(start[0] - end[0]) + abs(start[1] - end[1])\n",
    "\n",
    "\n",
    "def get_neighbors(position, grid, rows, cols):\n",
    "    x, y = position\n",
    "    neighbors = []\n",
    "    for dx, dy in [(-1, 0), (0, -1), (0, 1), (1, 0)]:  # Up, Left, Right, Down\n",
    "        nx, ny = x + dx, y + dy\n",
    "        if 0 <= nx < rows and 0 <= ny < cols and grid[nx][ny] != '%':\n",
    "            neighbors.append(((nx, ny), -(2 * dx + dy)))\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def a_star_search(pacman_pos, food_pos, grid, rows, cols, h=manhattan_distance):\n",
    "    frontier = []\n",
    "    heappush(frontier, (0 + h(pacman_pos, food_pos), 0,\n",
    "                        0, pacman_pos, [pacman_pos]))  # tuple(f-value, direction, cost, cur_pos, path)\n",
    "    visited = set()\n",
    "\n",
    "    while frontier:\n",
    "        _, _, cost, cur_pos, path = heappop(frontier)\n",
    "        visited.add(cur_pos)\n",
    "        if cur_pos == food_pos:\n",
    "            return path\n",
    "\n",
    "        neighbors = get_neighbors(cur_pos, grid, rows, cols)\n",
    "        for neighbor, direction in neighbors:\n",
    "            if neighbor not in visited:\n",
    "                heappush(frontier, (cost + 1 + h(neighbor, food_pos), direction,\n",
    "                                    cost + 1, neighbor, path + [neighbor]))\n",
    "\n",
    "    return []\n",
    "\n",
    "\n",
    "def initialize(grid: str) -> list[list]:\n",
    "    pacman_pos, food_pos, grid, rows, cols = parse_input(grid)\n",
    "    path = a_star_search(pacman_pos, food_pos, grid, rows, cols)\n",
    "    return [[str(x), str(y)] for x, y in path]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    grid = \"\"\"3 9\n",
    "5 1\n",
    "7 20\n",
    "%%%%%%%%%%%%%%%%%%%%\n",
    "%--------------%---%\n",
    "%-%%-%%-%%-%%-%%-%-%\n",
    "%--------P-------%-%\n",
    "%%%%%%%%%%%%%%%%%%-%\n",
    "%.-----------------%\n",
    "%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "\n",
    "    output = initialize(grid)\n",
    "    expected = [['3', '9'], ['3', '10'], ['3', '11'], ['3', '12'], ['3', '13'],\n",
    "                ['3', '14'], ['3', '15'], ['3', '16'], ['2', '16'], ['1', '16'],\n",
    "                ['1', '17'], ['1', '18'], ['2', '18'], ['3', '18'], ['4', '18'],\n",
    "                ['5', '18'], ['5', '17'], ['5', '16'], ['5', '15'], ['5', '14'],\n",
    "                ['5', '13'], ['5', '12'], ['5', '11'], ['5', '10'], ['5', '9'],\n",
    "                ['5', '8'], ['5', '7'], ['5', '6'], ['5', '5'], ['5', '4'],\n",
    "                ['5', '3'], ['5', '2'], ['5', '1']]\n",
    "\n",
    "    if output == expected:\n",
    "        print(\"Pass\")\n",
    "    else:\n",
    "        print(\"Incorrect\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import Optional, Union\n",
    "\n",
    "\n",
    "class KMeans:\n",
    "    '''\n",
    "    Sample Class for KMeans Clustering\n",
    "    DO NOT MODIFY any part of this code unless you are requested to do so.\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_clusters: int = 3,\n",
    "        max_iter: int = 30,\n",
    "        tol: float = 1e-4,\n",
    "        init: str = 'random',\n",
    "        n_init: int = 300,\n",
    "        seed: Optional[int] = None,\n",
    "        verbose: bool = False\n",
    "    ) -> None:\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.init = init\n",
    "        self.n_init = n_init\n",
    "        self.seed = seed\n",
    "        self.centroids: Optional[np.ndarray] = None\n",
    "        self.best_centroids: Optional[np.ndarray] = None\n",
    "        self.best_objective: float = np.inf\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "\n",
    "    def fit(self, X: np.ndarray, algorithm: str = 'lloyd') -> None:\n",
    "        for init in tqdm(range(self.n_init)):\n",
    "            self.centroids = self._initialize_centroids(X)\n",
    "\n",
    "            if init == 0:\n",
    "                self.best_centroids = self.centroids.copy()\n",
    "                self.best_objective = np.inf\n",
    "\n",
    "            if algorithm == 'lloyd':\n",
    "                self._lloyd(X)\n",
    "            elif algorithm == 'elkan':\n",
    "                self._elkan(X)\n",
    "            elif algorithm == 'hamerly':\n",
    "                self._hamerly(X)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown algorithm type\")\n",
    "\n",
    "        self.centroids = self.best_centroids\n",
    "\n",
    "    def _initialize_centroids(self, X: np.ndarray) -> np.ndarray:\n",
    "        if self.init == 'kmeans++':\n",
    "            return self._kmeans_pp(X)\n",
    "        return self._random_init(X)\n",
    "\n",
    "    def _random_init(self, X: np.ndarray) -> np.ndarray:\n",
    "        indices = np.random.choice(X.shape[0], self.n_clusters, replace=False)\n",
    "        return X[indices]\n",
    "\n",
    "    def _kmeans_pp(self, X: np.ndarray) -> np.ndarray:\n",
    "        centroids = []\n",
    "        centroids.append(X[np.random.choice(X.shape[0])])\n",
    "\n",
    "        for _ in range(1, self.n_clusters):\n",
    "            dist_sq = np.array([min([np.inner(c-x, c-x)\n",
    "                               for c in centroids]) for x in X])\n",
    "            probs = dist_sq / dist_sq.sum()\n",
    "            cumulative_probs = probs.cumsum()\n",
    "            r = np.random.rand()\n",
    "\n",
    "            for j, p in enumerate(cumulative_probs):\n",
    "                if r < p:\n",
    "                    i = j\n",
    "                    break\n",
    "\n",
    "            centroids.append(X[i])\n",
    "\n",
    "        return np.array(centroids)\n",
    "\n",
    "    def _lloyd(self, X: np.ndarray) -> None:\n",
    "        for _ in range(self.max_iter):\n",
    "            clusters = self._assign_clusters(X)\n",
    "            new_centroids = np.array([\n",
    "                X[clusters == i].mean(axis=0) if np.any(\n",
    "                    clusters == i) else self.centroids[i]\n",
    "                for i in range(self.n_clusters)\n",
    "            ])\n",
    "\n",
    "            shift = np.linalg.norm(self.centroids - new_centroids)\n",
    "            if shift <= self.tol:\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "            objective = self._compute_objective(X, clusters, self.centroids)\n",
    "\n",
    "            if objective < self.best_objective:\n",
    "                self.best_centroids = self.centroids.copy()\n",
    "                self.best_objective = objective\n",
    "\n",
    "    def _elkan(self, X: np.ndarray) -> None:\n",
    "        upper_bounds = np.full(X.shape[0], np.inf)\n",
    "        lower_bounds = np.zeros((X.shape[0], self.n_clusters))\n",
    "        centroid_dists = np.linalg.norm(\n",
    "            self.centroids[:, np.newaxis] - self.centroids, axis=2)\n",
    "\n",
    "        clusters = np.zeros(X.shape[0], dtype=int)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Step 1: Compute distances between centroids\n",
    "            centroid_dists = np.linalg.norm(\n",
    "                self.centroids[:, np.newaxis] - self.centroids, axis=2)\n",
    "\n",
    "            # Step 2: Update bounds\n",
    "            upper_bounds = np.linalg.norm(X - self.centroids[clusters], axis=1)\n",
    "            lower_bounds = np.maximum(\n",
    "                lower_bounds, centroid_dists[clusters] / 2)\n",
    "\n",
    "            # Step 3: Assignment step\n",
    "            reassignment_mask = upper_bounds > np.min(lower_bounds, axis=1)\n",
    "            distances = cdist(X[reassignment_mask], self.centroids)\n",
    "            clusters[reassignment_mask] = np.argmin(distances, axis=1)\n",
    "            upper_bounds[reassignment_mask] = distances[np.arange(\n",
    "                len(distances)), clusters[reassignment_mask]]\n",
    "\n",
    "            # Step 4: Update centroids\n",
    "            new_centroids = np.array([\n",
    "                X[clusters == i].mean(axis=0) if np.any(\n",
    "                    clusters == i) else self.centroids[i]\n",
    "                for i in range(self.n_clusters)\n",
    "            ])\n",
    "\n",
    "            # Compute the new objective value\n",
    "            new_objective = self._compute_objective(X, clusters, new_centroids)\n",
    "\n",
    "            # Update the best centroids if the objective improves\n",
    "            if new_objective < self.best_objective:\n",
    "                self.best_centroids = new_centroids.copy()\n",
    "                self.best_objective = new_objective\n",
    "\n",
    "            # Always update centroids\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "            # Check for convergence\n",
    "            if iteration % 10 == 0 and self.verbose:\n",
    "                print(f\"Iteration {iteration}: objective = {new_objective}\")\n",
    "\n",
    "            if np.linalg.norm(self.centroids - new_centroids) <= self.tol:\n",
    "                break\n",
    "\n",
    "    def _hamerly(self, X: np.ndarray) -> None:\n",
    "        upper_bounds = np.full(X.shape[0], np.inf)\n",
    "        lower_bounds = np.zeros(X.shape[0])\n",
    "        centroid_dists = np.linalg.norm(\n",
    "            self.centroids[:, np.newaxis] - self.centroids, axis=2)\n",
    "        clusters = np.zeros(X.shape[0], dtype=int)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Step 1: Compute distances between centroids\n",
    "            centroid_dists = np.linalg.norm(\n",
    "                self.centroids[:, np.newaxis] - self.centroids, axis=2)\n",
    "\n",
    "            # Step 2: Update bounds\n",
    "            upper_bounds = np.linalg.norm(X - self.centroids[clusters], axis=1)\n",
    "            lower_bounds = 0.5 * np.min(centroid_dists[clusters], axis=1)\n",
    "\n",
    "            # Step 3: Assignment step\n",
    "            reassignment_mask = upper_bounds > lower_bounds\n",
    "            distances = cdist(X[reassignment_mask], self.centroids)\n",
    "            clusters[reassignment_mask] = np.argmin(distances, axis=1)\n",
    "            upper_bounds[reassignment_mask] = distances[np.arange(\n",
    "                len(distances)), clusters[reassignment_mask]]\n",
    "\n",
    "            # Step 4: Update centroids\n",
    "            new_centroids = np.array([\n",
    "                X[clusters == i].mean(axis=0) if np.any(\n",
    "                    clusters == i) else self.centroids[i]\n",
    "                for i in range(self.n_clusters)\n",
    "            ])\n",
    "\n",
    "            # Compute the new objective value\n",
    "            new_objective = self._compute_objective(X, clusters, new_centroids)\n",
    "\n",
    "            # Update the best centroids if the objective improves\n",
    "            if new_objective < self.best_objective:\n",
    "                self.best_centroids = new_centroids.copy()\n",
    "                self.best_objective = new_objective\n",
    "\n",
    "            # Always update centroids\n",
    "            self.centroids = new_centroids\n",
    "\n",
    "            # Check for convergence\n",
    "            if iteration % 10 == 0 and self.verbose:\n",
    "                print(f\"Iteration {iteration}: objective = {new_objective}\")\n",
    "\n",
    "            if np.linalg.norm(self.centroids - new_centroids) <= self.tol:\n",
    "                break\n",
    "\n",
    "    def _assign_clusters(self, X: np.ndarray, point_index: Optional[int] = None, use_bounds: bool = False,\n",
    "                         upper_bounds: Optional[np.ndarray] = None,\n",
    "                         lower_bounds: Optional[np.ndarray] = None) -> Union[np.ndarray, int]:\n",
    "        if point_index is None:\n",
    "            if use_bounds and upper_bounds is not None and lower_bounds is not None:\n",
    "                distances = np.full((X.shape[0], self.n_clusters), np.inf)\n",
    "                for i in range(self.n_clusters):\n",
    "                    mask = upper_bounds < lower_bounds[:, i]\n",
    "                    distances[mask, i] = np.linalg.norm(\n",
    "                        X[mask] - self.centroids[i], axis=1)\n",
    "                return np.argmin(distances, axis=1)\n",
    "            else:\n",
    "                distances = cdist(X, self.centroids, 'euclidean')\n",
    "                return np.argmin(distances, axis=1)\n",
    "        else:\n",
    "            distances = cdist(X[point_index:point_index + 1],\n",
    "                              self.centroids, 'euclidean')\n",
    "            return np.argmin(distances)\n",
    "\n",
    "    def _compute_objective(self, X: np.ndarray, clusters: np.ndarray, centroids: np.ndarray) -> float:\n",
    "        objective = 0.0\n",
    "        for i in range(self.n_clusters):\n",
    "            mask = clusters == i\n",
    "            size = np.sum(mask)\n",
    "            objective += size * \\\n",
    "                np.sum(np.linalg.norm(X[mask] - centroids[i], axis=1) ** 2)\n",
    "        return objective\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self._assign_clusters(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
